{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb982a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20247e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reddit_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f81912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_username</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_created_utc</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5rlkl4</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Reese1993</td>\n",
       "      <td>Some of the worst places you donâ€™t realize unt...</td>\n",
       "      <td>131</td>\n",
       "      <td>2018-09-11T08:52:27</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e5rn12k</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Niasmomma99</td>\n",
       "      <td>When you feel perfectly well until you pull in...</td>\n",
       "      <td>123</td>\n",
       "      <td>2018-09-11T09:21:00</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5rhrre</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>crazynekosama</td>\n",
       "      <td>High turnover rate. If people aren't staying l...</td>\n",
       "      <td>318</td>\n",
       "      <td>2018-09-11T07:48:11</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5rf6iy</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>msstark</td>\n",
       "      <td>People talk about each other behind their backs.</td>\n",
       "      <td>167</td>\n",
       "      <td>2018-09-11T07:07:42</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5rf7y0</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>a-little-sleepy</td>\n",
       "      <td>If you come to work in a good mood and someone...</td>\n",
       "      <td>168</td>\n",
       "      <td>2018-09-11T07:08:20</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id post_id subreddit  author_username  \\\n",
       "0    e5rlkl4  9etcsl  AskWomen        Reese1993   \n",
       "1    e5rn12k  9etcsl  AskWomen      Niasmomma99   \n",
       "2    e5rhrre  9etcsl  AskWomen    crazynekosama   \n",
       "3    e5rf6iy  9etcsl  AskWomen          msstark   \n",
       "4    e5rf7y0  9etcsl  AskWomen  a-little-sleepy   \n",
       "\n",
       "                                        comment_body  comment_score  \\\n",
       "0  Some of the worst places you donâ€™t realize unt...            131   \n",
       "1  When you feel perfectly well until you pull in...            123   \n",
       "2  High turnover rate. If people aren't staying l...            318   \n",
       "3  People talk about each other behind their backs.             167   \n",
       "4  If you come to work in a good mood and someone...            168   \n",
       "\n",
       "   comment_created_utc  parent_id  is_top_level  \\\n",
       "0  2018-09-11T08:52:27  t3_9etcsl             1   \n",
       "1  2018-09-11T09:21:00  t3_9etcsl             1   \n",
       "2  2018-09-11T07:48:11  t3_9etcsl             1   \n",
       "3  2018-09-11T07:07:42  t3_9etcsl             1   \n",
       "4  2018-09-11T07:08:20  t3_9etcsl             1   \n",
       "\n",
       "                                         post_title post_text  \\\n",
       "0  What are some subtle signs of a toxic workplace?       NaN   \n",
       "1  What are some subtle signs of a toxic workplace?       NaN   \n",
       "2  What are some subtle signs of a toxic workplace?       NaN   \n",
       "3  What are some subtle signs of a toxic workplace?       NaN   \n",
       "4  What are some subtle signs of a toxic workplace?       NaN   \n",
       "\n",
       "      post_created_utc                                           post_url  \n",
       "0  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "1  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "2  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "3  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "4  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a17ad59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_username</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_created_utc</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5rlkl4</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Reese1993</td>\n",
       "      <td>Some of the worst places you donâ€™t realize unt...</td>\n",
       "      <td>131</td>\n",
       "      <td>2018-09-11T08:52:27</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e5rn12k</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Niasmomma99</td>\n",
       "      <td>When you feel perfectly well until you pull in...</td>\n",
       "      <td>123</td>\n",
       "      <td>2018-09-11T09:21:00</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5rhrre</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>crazynekosama</td>\n",
       "      <td>High turnover rate. If people aren't staying l...</td>\n",
       "      <td>318</td>\n",
       "      <td>2018-09-11T07:48:11</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5rf6iy</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>msstark</td>\n",
       "      <td>People talk about each other behind their backs.</td>\n",
       "      <td>167</td>\n",
       "      <td>2018-09-11T07:07:42</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5rf7y0</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>a-little-sleepy</td>\n",
       "      <td>If you come to work in a good mood and someone...</td>\n",
       "      <td>168</td>\n",
       "      <td>2018-09-11T07:08:20</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e5rh1na</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>ah04eo</td>\n",
       "      <td>Gossip, exclusion, managers pitting employees ...</td>\n",
       "      <td>153</td>\n",
       "      <td>2018-09-11T07:36:19</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5rpuwl</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>The boss insisting that the workplace is like ...</td>\n",
       "      <td>183</td>\n",
       "      <td>2018-09-11T10:22:33</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e5rfau4</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>aveclesmuguets</td>\n",
       "      <td>Gossip. Which bosses do not care to take care ...</td>\n",
       "      <td>62</td>\n",
       "      <td>2018-09-11T07:09:35</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e5rg0e8</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>blerrycat</td>\n",
       "      <td>Boss talks politics like everyone agrees.</td>\n",
       "      <td>49</td>\n",
       "      <td>2018-09-11T07:20:16</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e5rogpg</td>\n",
       "      <td>9etcsl</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Miscommunication between everyone in the workp...</td>\n",
       "      <td>81</td>\n",
       "      <td>2018-09-11T09:51:09</td>\n",
       "      <td>t3_9etcsl</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some subtle signs of a toxic workplace?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-11T07:04:12</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/9et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id post_id subreddit  author_username  \\\n",
       "0    e5rlkl4  9etcsl  AskWomen        Reese1993   \n",
       "1    e5rn12k  9etcsl  AskWomen      Niasmomma99   \n",
       "2    e5rhrre  9etcsl  AskWomen    crazynekosama   \n",
       "3    e5rf6iy  9etcsl  AskWomen          msstark   \n",
       "4    e5rf7y0  9etcsl  AskWomen  a-little-sleepy   \n",
       "5    e5rh1na  9etcsl  AskWomen           ah04eo   \n",
       "6    e5rpuwl  9etcsl  AskWomen        [deleted]   \n",
       "7    e5rfau4  9etcsl  AskWomen   aveclesmuguets   \n",
       "8    e5rg0e8  9etcsl  AskWomen        blerrycat   \n",
       "9    e5rogpg  9etcsl  AskWomen        [deleted]   \n",
       "\n",
       "                                        comment_body  comment_score  \\\n",
       "0  Some of the worst places you donâ€™t realize unt...            131   \n",
       "1  When you feel perfectly well until you pull in...            123   \n",
       "2  High turnover rate. If people aren't staying l...            318   \n",
       "3  People talk about each other behind their backs.             167   \n",
       "4  If you come to work in a good mood and someone...            168   \n",
       "5  Gossip, exclusion, managers pitting employees ...            153   \n",
       "6  The boss insisting that the workplace is like ...            183   \n",
       "7  Gossip. Which bosses do not care to take care ...             62   \n",
       "8         Boss talks politics like everyone agrees.              49   \n",
       "9  Miscommunication between everyone in the workp...             81   \n",
       "\n",
       "   comment_created_utc  parent_id  is_top_level  \\\n",
       "0  2018-09-11T08:52:27  t3_9etcsl             1   \n",
       "1  2018-09-11T09:21:00  t3_9etcsl             1   \n",
       "2  2018-09-11T07:48:11  t3_9etcsl             1   \n",
       "3  2018-09-11T07:07:42  t3_9etcsl             1   \n",
       "4  2018-09-11T07:08:20  t3_9etcsl             1   \n",
       "5  2018-09-11T07:36:19  t3_9etcsl             1   \n",
       "6  2018-09-11T10:22:33  t3_9etcsl             1   \n",
       "7  2018-09-11T07:09:35  t3_9etcsl             1   \n",
       "8  2018-09-11T07:20:16  t3_9etcsl             1   \n",
       "9  2018-09-11T09:51:09  t3_9etcsl             1   \n",
       "\n",
       "                                         post_title post_text  \\\n",
       "0  What are some subtle signs of a toxic workplace?       NaN   \n",
       "1  What are some subtle signs of a toxic workplace?       NaN   \n",
       "2  What are some subtle signs of a toxic workplace?       NaN   \n",
       "3  What are some subtle signs of a toxic workplace?       NaN   \n",
       "4  What are some subtle signs of a toxic workplace?       NaN   \n",
       "5  What are some subtle signs of a toxic workplace?       NaN   \n",
       "6  What are some subtle signs of a toxic workplace?       NaN   \n",
       "7  What are some subtle signs of a toxic workplace?       NaN   \n",
       "8  What are some subtle signs of a toxic workplace?       NaN   \n",
       "9  What are some subtle signs of a toxic workplace?       NaN   \n",
       "\n",
       "      post_created_utc                                           post_url  \n",
       "0  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "1  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "2  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "3  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "4  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "5  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "6  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "7  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "8  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  \n",
       "9  2018-09-11T07:04:12  https://www.reddit.com/r/AskWomen/comments/9et...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1045c913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25148, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bdc4499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_id', 'post_id', 'subreddit', 'author_username', 'comment_body',\n",
       "       'comment_score', 'comment_created_utc', 'parent_id', 'is_top_level',\n",
       "       'post_title', 'post_text', 'post_created_utc', 'post_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22f1e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment_id',\n",
       " 'post_id',\n",
       " 'subreddit',\n",
       " 'author_username',\n",
       " 'comment_body',\n",
       " 'comment_score',\n",
       " 'comment_created_utc',\n",
       " 'parent_id',\n",
       " 'is_top_level',\n",
       " 'post_title',\n",
       " 'post_text',\n",
       " 'post_created_utc',\n",
       " 'post_url']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53305468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25148 entries, 0 to 25147\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comment_id           25148 non-null  object\n",
      " 1   post_id              25148 non-null  object\n",
      " 2   subreddit            25148 non-null  object\n",
      " 3   author_username      25148 non-null  object\n",
      " 4   comment_body         25148 non-null  object\n",
      " 5   comment_score        25148 non-null  int64 \n",
      " 6   comment_created_utc  25148 non-null  object\n",
      " 7   parent_id            25148 non-null  object\n",
      " 8   is_top_level         25148 non-null  int64 \n",
      " 9   post_title           25148 non-null  object\n",
      " 10  post_text            17705 non-null  object\n",
      " 11  post_created_utc     25148 non-null  object\n",
      " 12  post_url             25148 non-null  object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21acb3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_score</th>\n",
       "      <th>is_top_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25148.000000</td>\n",
       "      <td>25148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.564299</td>\n",
       "      <td>0.660967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>157.905318</td>\n",
       "      <td>0.473390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-229.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9049.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_score  is_top_level\n",
       "count   25148.000000  25148.000000\n",
       "mean       17.564299      0.660967\n",
       "std       157.905318      0.473390\n",
       "min      -229.000000      0.000000\n",
       "25%         1.000000      0.000000\n",
       "50%         1.000000      1.000000\n",
       "75%         3.000000      1.000000\n",
       "max      9049.000000      1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e92de70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_username</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_created_utc</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148.000000</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148.000000</td>\n",
       "      <td>25148</td>\n",
       "      <td>17705</td>\n",
       "      <td>25148</td>\n",
       "      <td>25148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25148</td>\n",
       "      <td>235</td>\n",
       "      <td>2</td>\n",
       "      <td>15721</td>\n",
       "      <td>24790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24924</td>\n",
       "      <td>5616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>106</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e5rlkl4</td>\n",
       "      <td>ovt9k9</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>This comment or post has been removed for dera...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-02T04:39:33</td>\n",
       "      <td>t3_ovt9k9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What has made you realize you were getting old?</td>\n",
       "      <td>I (25M) recently took my little sister (14) ou...</td>\n",
       "      <td>2021-08-01T19:38:14</td>\n",
       "      <td>https://www.reddit.com/r/AskMen/comments/ovt9k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>16812</td>\n",
       "      <td>3847</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.564299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.905318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-229.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9049.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id post_id subreddit author_username  \\\n",
       "count       25148   25148     25148           25148   \n",
       "unique      25148     235         2           15721   \n",
       "top       e5rlkl4  ovt9k9    AskMen       [deleted]   \n",
       "freq            1    2500     16812            3847   \n",
       "mean          NaN     NaN       NaN             NaN   \n",
       "std           NaN     NaN       NaN             NaN   \n",
       "min           NaN     NaN       NaN             NaN   \n",
       "25%           NaN     NaN       NaN             NaN   \n",
       "50%           NaN     NaN       NaN             NaN   \n",
       "75%           NaN     NaN       NaN             NaN   \n",
       "max           NaN     NaN       NaN             NaN   \n",
       "\n",
       "                                             comment_body  comment_score  \\\n",
       "count                                               25148   25148.000000   \n",
       "unique                                              24790            NaN   \n",
       "top     This comment or post has been removed for dera...            NaN   \n",
       "freq                                                   28            NaN   \n",
       "mean                                                  NaN      17.564299   \n",
       "std                                                   NaN     157.905318   \n",
       "min                                                   NaN    -229.000000   \n",
       "25%                                                   NaN       1.000000   \n",
       "50%                                                   NaN       1.000000   \n",
       "75%                                                   NaN       3.000000   \n",
       "max                                                   NaN    9049.000000   \n",
       "\n",
       "        comment_created_utc  parent_id  is_top_level  \\\n",
       "count                 25148      25148  25148.000000   \n",
       "unique                24924       5616           NaN   \n",
       "top     2021-08-02T04:39:33  t3_ovt9k9           NaN   \n",
       "freq                      3       2500           NaN   \n",
       "mean                    NaN        NaN      0.660967   \n",
       "std                     NaN        NaN      0.473390   \n",
       "min                     NaN        NaN      0.000000   \n",
       "25%                     NaN        NaN      0.000000   \n",
       "50%                     NaN        NaN      1.000000   \n",
       "75%                     NaN        NaN      1.000000   \n",
       "max                     NaN        NaN      1.000000   \n",
       "\n",
       "                                             post_title  \\\n",
       "count                                             25148   \n",
       "unique                                              232   \n",
       "top     What has made you realize you were getting old?   \n",
       "freq                                               2500   \n",
       "mean                                                NaN   \n",
       "std                                                 NaN   \n",
       "min                                                 NaN   \n",
       "25%                                                 NaN   \n",
       "50%                                                 NaN   \n",
       "75%                                                 NaN   \n",
       "max                                                 NaN   \n",
       "\n",
       "                                                post_text  \\\n",
       "count                                               17705   \n",
       "unique                                                106   \n",
       "top     I (25M) recently took my little sister (14) ou...   \n",
       "freq                                                 2500   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "           post_created_utc                                           post_url  \n",
       "count                 25148                                              25148  \n",
       "unique                  235                                                235  \n",
       "top     2021-08-01T19:38:14  https://www.reddit.com/r/AskMen/comments/ovt9k...  \n",
       "freq                   2500                                               2500  \n",
       "mean                    NaN                                                NaN  \n",
       "std                     NaN                                                NaN  \n",
       "min                     NaN                                                NaN  \n",
       "25%                     NaN                                                NaN  \n",
       "50%                     NaN                                                NaN  \n",
       "75%                     NaN                                                NaN  \n",
       "max                     NaN                                                NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15bc56a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id                0\n",
       "post_id                   0\n",
       "subreddit                 0\n",
       "author_username           0\n",
       "comment_body              0\n",
       "comment_score             0\n",
       "comment_created_utc       0\n",
       "parent_id                 0\n",
       "is_top_level              0\n",
       "post_title                0\n",
       "post_text              7443\n",
       "post_created_utc          0\n",
       "post_url                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a52617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /opt/anaconda3/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59b0d970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REDDIT SENTIMENT ANALYSIS\n",
      "======================================================================\n",
      "\n",
      " Loading Reddit data...\n",
      " Loaded 25,148 comments\n",
      "\n",
      "Columns in your data:\n",
      "['comment_id', 'post_id', 'subreddit', 'author_username', 'comment_body', 'comment_score', 'comment_created_utc', 'parent_id', 'is_top_level', 'post_title', 'post_text', 'post_created_utc', 'post_url']\n",
      "\n",
      " Initializing sentiment analyzer...\n",
      " Ready to analyze!\n",
      "\n",
      " Analyzing 25,148 comments...\n",
      "This may take a few minutes for large datasets...\n",
      "  Processed 5,000/25,148 comments...\n",
      "  Processed 10,000/25,148 comments...\n",
      "  Processed 15,000/25,148 comments...\n",
      "  Processed 20,000/25,148 comments...\n",
      "  Processed 25,000/25,148 comments...\n",
      "âœ“ Completed analyzing 25,148 comments!\n",
      "\n",
      " Adding sentiment results to dataframe...\n",
      " Sentiment scores added!\n",
      "\n",
      "======================================================================\n",
      "RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      " Sentiment Distribution:\n",
      "sentiment_label\n",
      "Positive    12310\n",
      "Negative     7288\n",
      "Neutral      5550\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Sentiment Percentages:\n",
      "  Positive: 49.0%\n",
      "  Negative: 29.0%\n",
      "  Neutral: 22.1%\n",
      "\n",
      " Average Sentiment Score: 0.139\n",
      "   Standard Deviation: 0.535\n",
      "\n",
      "======================================================================\n",
      "SENTIMENT BY SUBREDDIT\n",
      "======================================================================\n",
      "\n",
      "            Avg Sentiment  Comment Count  \\\n",
      "subreddit                                 \n",
      "AskMen             0.151          16812   \n",
      "AskWomen           0.115           8336   \n",
      "\n",
      "                                          Label Distribution  \n",
      "subreddit                                                     \n",
      "AskMen     {'Positive': 8093, 'Negative': 4382, 'Neutral'...  \n",
      "AskWomen   {'Positive': 4217, 'Negative': 2906, 'Neutral'...  \n",
      "\n",
      "======================================================================\n",
      "EXAMPLES\n",
      "======================================================================\n",
      "\n",
      " Most Positive Comments:\n",
      "\n",
      "  Score: 0.999\n",
      "  Subreddit: AskWomen\n",
      "  Comment: **The U.S. system has gradually eroded to demonize workers, but  canonize bosses and the wealthy industrialists.**\n",
      "\n",
      "That's why poor folks go to prison...\n",
      "\n",
      "  Score: 0.999\n",
      "  Subreddit: AskMen\n",
      "  Comment: Lessons from a young guy (was 27 when I started managing) in order to be at least an alright manager to older people:\n",
      "\n",
      "1. Have your bosses have your b...\n",
      "\n",
      "  Score: 0.999\n",
      "  Subreddit: AskMen\n",
      "  Comment: Most jobs are meant to create revenue with minimal cost, not to make you feel valued or worthwhile. Note I said most jobs.\n",
      "\n",
      "Your sense of self worth i...\n",
      "\n",
      "  Score: 0.999\n",
      "  Subreddit: AskWomen\n",
      "  Comment: Reading through the replies so far, reddit works in some fucked up places!\n",
      "\n",
      "I have been in shitty work cultures before, but now I am in a great enviro...\n",
      "\n",
      "  Score: 0.999\n",
      "  Subreddit: AskWomen\n",
      "  Comment: Make friends. I get that they're your coworkers and there needs to be some professional boundaries but you're at work for a large percentage of your d...\n",
      "\n",
      "\n",
      " Most Negative Comments:\n",
      "\n",
      "  Score: -0.998\n",
      "  Subreddit: AskMen\n",
      "  Comment: Both were named Lisa at papa johns. \n",
      "\n",
      "First was a total drama queen and an overall piece of shit. Some of the stupid shit she did: Stole $300 from the...\n",
      "\n",
      "  Score: -0.997\n",
      "  Subreddit: AskWomen\n",
      "  Comment: Yes. The first time I didn't want to speak up about that mangers name calling but friends convinced me to. His initial strategy was deny deny deny you...\n",
      "\n",
      "  Score: -0.997\n",
      "  Subreddit: AskMen\n",
      "  Comment: My bosses had established a method for dealing with mistakes by essentially letting the company lose money to teach the person a lesson. We're not tal...\n",
      "\n",
      "  Score: -0.997\n",
      "  Subreddit: AskMen\n",
      "  Comment: Old Ken.  He was a right frozen piece of diarrhea.\n",
      "\n",
      "Compulsive gambler:  His worse loss was $15K on the horses.  I remember the tow truck towing away ...\n",
      "\n",
      "  Score: -0.997\n",
      "  Subreddit: AskWomen\n",
      "  Comment: I wouldn't necessarily say I was ever a *boss*. But I used to be a supervisor and charged with hiring/termination. \n",
      "\n",
      "I should preface this by saying t...\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      " Saved visualization: reddit_sentiment_analysis.png\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      " Saved results to: reddit_data_with_sentiment.csv\n",
      "  Total rows: 25,148\n",
      "  Total columns: 15\n",
      "\n",
      " New columns added:\n",
      "  - sentiment_score (numerical: -1 to +1)\n",
      "  - sentiment_label (categorical: Positive/Neutral/Negative)\n",
      "\n",
      "======================================================================\n",
      "ADDITIONAL INSIGHTS\n",
      "======================================================================\n",
      "\n",
      " Sentiment by Comment Type:\n",
      "  Top-Level Comment: 0.141 (n=16,622)\n",
      "  Reply: 0.135 (n=8,526)\n",
      "\n",
      " Analyzing temporal patterns...\n",
      "  Data spans from 2018-03 to 2025-11\n",
      "  Average sentiment over time ranges from -0.409 to 0.696\n",
      "\n",
      "ðŸ”— Correlation between comment score and sentiment: -0.005\n",
      "\n",
      "======================================================================\n",
      " ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      " Files created:\n",
      "   - reddit_data_with_sentiment.csv (your data with sentiment)\n",
      "   - reddit_sentiment_analysis.png (visualizations)\n",
      "\n",
      " Key findings:\n",
      "   - Total comments analyzed: 25,148\n",
      "   - Average sentiment: 0.139\n",
      "   - Most common sentiment: Positive\n",
      "   - Positive comments: 12,310 (49.0%)\n",
      "   - Negative comments: 7,288 (29.0%)\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SENTIMENT ANALYSIS FOR REDDIT DATA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"REDDIT SENTIMENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD YOUR DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Loading Reddit data...\")\n",
    "\n",
    "\n",
    "df = pd.read_csv('reddit_data.csv')\n",
    "\n",
    "print(f\" Loaded {len(df):,} comments\")\n",
    "print(f\"\\nColumns in your data:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: INITIALIZE SENTIMENT ANALYZER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Initializing sentiment analyzer...\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "print(\" Ready to analyze!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: ANALYZE SENTIMENT FOR EACH COMMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n Analyzing {len(df):,} comments...\")\n",
    "print(\"This may take a few minutes for large datasets...\")\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    # Get the comment text\n",
    "    comment_text = row['comment_body']\n",
    "    \n",
    "    # Handle empty or missing comments\n",
    "    if pd.isna(comment_text) or str(comment_text).strip() == \"\":\n",
    "        sentiment_score = 0.0\n",
    "        sentiment_label = 'Neutral'\n",
    "    else:\n",
    "        # Analyze sentiment\n",
    "        scores = analyzer.polarity_scores(str(comment_text))\n",
    "        sentiment_score = scores['compound']\n",
    "        \n",
    "        # Classify\n",
    "        if sentiment_score >= 0.05:\n",
    "            sentiment_label = 'Positive'\n",
    "        elif sentiment_score <= -0.05:\n",
    "            sentiment_label = 'Negative'\n",
    "        else:\n",
    "            sentiment_label = 'Neutral'\n",
    "    \n",
    "    results.append({\n",
    "        'sentiment_score': sentiment_score,\n",
    "        'sentiment_label': sentiment_label\n",
    "    })\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"  Processed {idx + 1:,}/{len(df):,} comments...\")\n",
    "\n",
    "print(f\"âœ“ Completed analyzing {len(df):,} comments!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: ADD RESULTS TO DATAFRAME\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Adding sentiment results to dataframe...\")\n",
    "\n",
    "# Convert results to dataframe\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "\n",
    "# Add to original dataframe\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "print(\" Sentiment scores added!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: SHOW RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Sentiment Distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "print(\"\\n Sentiment Percentages:\")\n",
    "sentiment_pct = df['sentiment_label'].value_counts(normalize=True) * 100\n",
    "for label, pct in sentiment_pct.items():\n",
    "    print(f\"  {label}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\n Average Sentiment Score: {df['sentiment_score'].mean():.3f}\")\n",
    "print(f\"   Standard Deviation: {df['sentiment_score'].std():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: SENTIMENT BY SUBREDDIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SENTIMENT BY SUBREDDIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "subreddit_stats = df.groupby('subreddit').agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'comment_id': 'count',\n",
    "    'sentiment_label': lambda x: x.value_counts().to_dict()\n",
    "}).round(3)\n",
    "\n",
    "subreddit_stats.columns = ['Avg Sentiment', 'Comment Count', 'Label Distribution']\n",
    "\n",
    "print(\"\\n\", subreddit_stats)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: SHOW EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXAMPLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Most Positive Comments:\")\n",
    "top_positive = df.nlargest(5, 'sentiment_score')\n",
    "for idx, row in top_positive.iterrows():\n",
    "    print(f\"\\n  Score: {row['sentiment_score']:.3f}\")\n",
    "    print(f\"  Subreddit: {row['subreddit']}\")\n",
    "    print(f\"  Comment: {str(row['comment_body'])[:150]}...\")\n",
    "\n",
    "print(\"\\n\\n Most Negative Comments:\")\n",
    "top_negative = df.nsmallest(5, 'sentiment_score')\n",
    "for idx, row in top_negative.iterrows():\n",
    "    print(f\"\\n  Score: {row['sentiment_score']:.3f}\")\n",
    "    print(f\"  Subreddit: {row['subreddit']}\")\n",
    "    print(f\"  Comment: {str(row['comment_body'])[:150]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Reddit Sentiment Analysis Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Chart 1: Sentiment Distribution (Bar Chart)\n",
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "colors = {'Positive': '#2ecc71', 'Neutral': '#95a5a6', 'Negative': '#e74c3c'}\n",
    "bar_colors = [colors.get(label, '#3498db') for label in sentiment_counts.index]\n",
    "\n",
    "axes[0].bar(sentiment_counts.index, sentiment_counts.values, color=bar_colors)\n",
    "axes[0].set_title('Sentiment Distribution', fontsize=14)\n",
    "axes[0].set_ylabel('Number of Comments', fontsize=12)\n",
    "axes[0].set_xlabel('Sentiment', fontsize=12)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(sentiment_counts.values):\n",
    "    axes[0].text(i, v, f'{v:,}\\n({v/len(df)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Chart 2: Sentiment Score Distribution (Histogram)\n",
    "axes[1].hist(df['sentiment_score'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(df['sentiment_score'].mean(), color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Mean: {df[\"sentiment_score\"].mean():.3f}')\n",
    "axes[1].set_title('Sentiment Score Distribution', fontsize=14)\n",
    "axes[1].set_xlabel('Sentiment Score', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Chart 3: Sentiment by Subreddit\n",
    "subreddit_sentiment = df.groupby('subreddit')['sentiment_score'].mean().sort_values()\n",
    "colors_sub = ['#e74c3c' if x < -0.05 else '#2ecc71' if x > 0.05 else '#95a5a6' \n",
    "              for x in subreddit_sentiment.values]\n",
    "\n",
    "axes[2].barh(subreddit_sentiment.index, subreddit_sentiment.values, color=colors_sub)\n",
    "axes[2].set_title('Average Sentiment by Subreddit', fontsize=14)\n",
    "axes[2].set_xlabel('Average Sentiment Score', fontsize=12)\n",
    "axes[2].axvline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[2].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reddit_sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\" Saved visualization: reddit_sentiment_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: SAVE RESULTS TO CSV\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_file = 'reddit_data_with_sentiment.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\" Saved results to: {output_file}\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n",
    "print(f\"\\n New columns added:\")\n",
    "print(f\"  - sentiment_score (numerical: -1 to +1)\")\n",
    "print(f\"  - sentiment_label (categorical: Positive/Neutral/Negative)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: ADDITIONAL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADDITIONAL INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Top-level vs Reply comments\n",
    "if 'is_top_level' in df.columns:\n",
    "    print(\"\\n Sentiment by Comment Type:\")\n",
    "    for is_top in df['is_top_level'].unique():\n",
    "        comment_type = \"Top-Level Comment\" if is_top == 1 else \"Reply\"\n",
    "        subset = df[df['is_top_level'] == is_top]\n",
    "        avg_sentiment = subset['sentiment_score'].mean()\n",
    "        print(f\"  {comment_type}: {avg_sentiment:.3f} (n={len(subset):,})\")\n",
    "\n",
    "# Sentiment over time\n",
    "if 'comment_created_utc' in df.columns:\n",
    "    print(\"\\n Analyzing temporal patterns...\")\n",
    "    df['comment_date'] = pd.to_datetime(df['comment_created_utc'])\n",
    "    df['year_month'] = df['comment_date'].dt.to_period('M')\n",
    "    \n",
    "    temporal = df.groupby('year_month')['sentiment_score'].mean()\n",
    "    print(f\"  Data spans from {temporal.index.min()} to {temporal.index.max()}\")\n",
    "    print(f\"  Average sentiment over time ranges from {temporal.min():.3f} to {temporal.max():.3f}\")\n",
    "\n",
    "# Comment score correlation\n",
    "if 'comment_score' in df.columns:\n",
    "    correlation = df['comment_score'].corr(df['sentiment_score'])\n",
    "    print(f\"\\nðŸ”— Correlation between comment score and sentiment: {correlation:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    " Files created:\n",
    "   - reddit_data_with_sentiment.csv (your data with sentiment)\n",
    "   - reddit_sentiment_analysis.png (visualizations)\n",
    "\n",
    " Key findings:\n",
    "   - Total comments analyzed: {len(df):,}\n",
    "   - Average sentiment: {df['sentiment_score'].mean():.3f}\n",
    "   - Most common sentiment: {df['sentiment_label'].value_counts().index[0]}\n",
    "   - Positive comments: {(df['sentiment_label']=='Positive').sum():,} ({(df['sentiment_label']=='Positive').sum()/len(df)*100:.1f}%)\n",
    "   - Negative comments: {(df['sentiment_label']=='Negative').sum():,} ({(df['sentiment_label']=='Negative').sum()/len(df)*100:.1f}%)\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "702cf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(\"glassdoor_health_care_reviews.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aa41609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first rows:\n",
      "   review_id       company_name    industry                     job_title  \\\n",
      "0          1  Boston Scientific  Healthcare           Process engineer ii   \n",
      "1          2  Boston Scientific  Healthcare  Ep senior mapping specialist   \n",
      "2          3  Boston Scientific  Healthcare      Manufacturing technician   \n",
      "3          4  Boston Scientific  Healthcare             Territory manager   \n",
      "4          5  Boston Scientific  Healthcare      Senior financial analyst   \n",
      "\n",
      "  review_date  overall_rating  \\\n",
      "0  2025-11-07             5.0   \n",
      "1  2025-11-02             2.0   \n",
      "2  2025-11-03             5.0   \n",
      "3  2025-11-08             4.0   \n",
      "4  2025-10-29             2.0   \n",
      "\n",
      "                                           pros_text  \\\n",
      "0                    Great culture with smart people   \n",
      "1  Benefits - good health and dental insurance ES...   \n",
      "2  Great work environment A lot of help from uppe...   \n",
      "3               Above average pay and great benefits   \n",
      "4                  Great pay and some solid benefits   \n",
      "\n",
      "                                           cons_text  \n",
      "0  Growing pains that come along with a growing o...  \n",
      "1  Short-Staffed Teams - this company was previou...  \n",
      "2  Projects you worked hard at can get over looke...  \n",
      "3               Work life balance can be challenging  \n",
      "4  Culture differs from team to team, really need...  \n"
     ]
    }
   ],
   "source": [
    "# --- Preview ---\n",
    "print(\"first rows:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b997a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape (rows, columns):\n",
      "(1500, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensions ---\n",
    "print(\"\\nshape (rows, columns):\")\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e59aa67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "variable names:\n",
      "['review_id', 'company_name', 'industry', 'job_title', 'review_date', 'overall_rating', 'pros_text', 'cons_text']\n"
     ]
    }
   ],
   "source": [
    "# --- Variable names ---\n",
    "print(\"\\nvariable names:\")\n",
    "print(list(df.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3aa76d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   review_id       1500 non-null   int64  \n",
      " 1   company_name    1500 non-null   object \n",
      " 2   industry        1500 non-null   object \n",
      " 3   job_title       1500 non-null   object \n",
      " 4   review_date     1500 non-null   object \n",
      " 5   overall_rating  1500 non-null   float64\n",
      " 6   pros_text       1500 non-null   object \n",
      " 7   cons_text       1500 non-null   object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 93.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --- Structure ---\n",
    "print(\"\\ndata info:\")\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ee6290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary stats\n",
      "          review_id company_name    industry           job_title review_date  \\\n",
      "count   1500.000000         1500        1500                1500        1500   \n",
      "unique          NaN            6           1                 357         222   \n",
      "top             NaN       Pfizer  Healthcare  Anonymous employee  2025-10-14   \n",
      "freq            NaN          281        1500                 152          33   \n",
      "mean     750.500000          NaN         NaN                 NaN         NaN   \n",
      "std      433.157015          NaN         NaN                 NaN         NaN   \n",
      "min        1.000000          NaN         NaN                 NaN         NaN   \n",
      "25%      375.750000          NaN         NaN                 NaN         NaN   \n",
      "50%      750.500000          NaN         NaN                 NaN         NaN   \n",
      "75%     1125.250000          NaN         NaN                 NaN         NaN   \n",
      "max     1500.000000          NaN         NaN                 NaN         NaN   \n",
      "\n",
      "        overall_rating                                          pros_text  \\\n",
      "count      1500.000000                                               1500   \n",
      "unique             NaN                                                610   \n",
      "top                NaN  Great mission and impact in the healthcare spa...   \n",
      "freq               NaN                                                  7   \n",
      "mean          3.844667                                                NaN   \n",
      "std           1.115961                                                NaN   \n",
      "min           1.000000                                                NaN   \n",
      "25%           3.000000                                                NaN   \n",
      "50%           4.000000                                                NaN   \n",
      "75%           5.000000                                                NaN   \n",
      "max           5.000000                                                NaN   \n",
      "\n",
      "                                                cons_text  \n",
      "count                                                1500  \n",
      "unique                                                606  \n",
      "top     Leadership often feels disconnected from the r...  \n",
      "freq                                                    7  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "# --- Summary stats ---\n",
    "print(\"\\nsummary stats\")\n",
    "print(df.describe(include='all'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efc2b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "missing value count:\n",
      "review_id         0\n",
      "company_name      0\n",
      "industry          0\n",
      "job_title         0\n",
      "review_date       0\n",
      "overall_rating    0\n",
      "pros_text         0\n",
      "cons_text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Missing values ---\n",
    "print(\"\\nmissing value count:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc179436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GLASSDOOR HEALTHCARE SENTIMENT ANALYSIS\n",
      "======================================================================\n",
      "\n",
      " Loading Glassdoor Healthcare reviews...\n",
      "âœ“ Loaded 1,500 reviews\n",
      "\n",
      "Columns in your data:\n",
      "['review_id', 'company_name', 'industry', 'job_title', 'review_date', 'overall_rating', 'pros_text', 'cons_text']\n",
      "\n",
      " Initializing sentiment analyzer...\n",
      " Ready to analyze!\n",
      "\n",
      " Analyzing 1,500 reviews...\n",
      "Analyzing both PROS and CONS sections...\n",
      "  Processed 500/1,500 reviews...\n",
      "  Processed 1,000/1,500 reviews...\n",
      "  Processed 1,500/1,500 reviews...\n",
      " Completed analyzing 1,500 reviews!\n",
      "\n",
      " Adding sentiment results to dataframe...\n",
      " Sentiment scores added!\n",
      "\n",
      "======================================================================\n",
      "RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      " COMBINED Sentiment Distribution:\n",
      "combined_sentiment_label\n",
      "Positive    1268\n",
      "Negative     122\n",
      "Neutral      110\n",
      "Name: count, dtype: int64\n",
      "\n",
      " COMBINED Sentiment Percentages:\n",
      "  Positive: 84.5%\n",
      "  Negative: 8.1%\n",
      "  Neutral: 7.3%\n",
      "\n",
      " Average Sentiment Scores:\n",
      "   PROS:     0.623\n",
      "   CONS:     0.016\n",
      "   COMBINED: 0.320\n",
      "\n",
      "======================================================================\n",
      "SENTIMENT BY COMPANY\n",
      "======================================================================\n",
      "\n",
      "                    Avg Sentiment  Review Count  Avg Rating\n",
      "company_name                                              \n",
      "Boston Scientific          0.353           266       3.850\n",
      "Johnson & Johnson          0.345           266       4.086\n",
      "Mayo Clinic                0.316           140       3.800\n",
      "Pfizer                     0.306           281       3.609\n",
      "GSK                        0.303           273       3.832\n",
      "Roche                      0.295           274       3.883\n",
      "\n",
      "======================================================================\n",
      "examples\n",
      "======================================================================\n",
      "\n",
      " Most Positive Reviews:\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Associate scientist\n",
      "  Score: 0.951\n",
      "  Pros: Great work culture, friendly atmosphere. Benefits are great, different site events are fun and inclu...\n",
      "  Cons: Not organized/managers are not in sync with each other when department is bigger. Sometimes feels li...\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Associate scientist\n",
      "  Score: 0.951\n",
      "  Pros: Great work culture, friendly atmosphere. Benefits are great, different site events are fun and inclu...\n",
      "  Cons: Not organized/managers are not in sync with each other when department is bigger. Sometimes feels li...\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Associate scientist\n",
      "  Score: 0.951\n",
      "  Pros: Great work culture, friendly atmosphere. Benefits are great, different site events are fun and inclu...\n",
      "  Cons: Not organized/managers are not in sync with each other when department is bigger. Sometimes feels li...\n",
      "\n",
      "\n",
      " Most Negative Reviews:\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Senior leader\n",
      "  Score: -0.592\n",
      "  Pros: No pros, just a lot of cons, specially at this site. All older employees have their kids and family ...\n",
      "  Cons: Perhaps they get the award for being the the most miserable vial work environment for all levels in ...\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Senior leader\n",
      "  Score: -0.592\n",
      "  Pros: No pros, just a lot of cons, specially at this site. All older employees have their kids and family ...\n",
      "  Cons: Perhaps they get the award for being the the most miserable vial work environment for all levels in ...\n",
      "\n",
      "  Company: Pfizer\n",
      "  Job Title: Senior leader\n",
      "  Score: -0.592\n",
      "  Pros: No pros, just a lot of cons, specially at this site. All older employees have their kids and family ...\n",
      "  Cons: Perhaps they get the award for being the the most miserable vial work environment for all levels in ...\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      " Saved visualization: glassdoor_healthcare_sentiment_analysis.png\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "âœ“ Saved results to: glassdoor_health_care_reviews_with_sentiment.csv\n",
      "  Total rows: 1,500\n",
      "  Total columns: 14\n",
      "\n",
      "New columns added:\n",
      "  - pros_sentiment_score\n",
      "  - pros_sentiment_label\n",
      "  - cons_sentiment_score\n",
      "  - cons_sentiment_label\n",
      "  - combined_sentiment_score (MAIN METRIC)\n",
      "  - combined_sentiment_label\n",
      "\n",
      "======================================================================\n",
      "ADDITIONAL INSIGHTS\n",
      "======================================================================\n",
      "\n",
      " Correlation between star rating and sentiment: 0.175\n",
      "\n",
      " Sentiment by Job Title (Top 10 most common):\n",
      "                              Avg Sentiment  Count\n",
      "job_title                                         \n",
      "Cyber security sme                    0.879      4\n",
      "Senior r&d engineer                   0.827      4\n",
      "Senior project manager                0.818      4\n",
      "Principal manager                     0.816      3\n",
      "Car-t manufacturing operator          0.815      4\n",
      "Marketing                             0.789      4\n",
      "Process engineer i                    0.724      5\n",
      "Program manager                       0.721      4\n",
      "Scrum master                          0.716      4\n",
      "Senior level                          0.709      5\n",
      "\n",
      " Temporal Analysis:\n",
      "  Data spans from 2024-01 to 2025-11\n",
      "  Sentiment ranges from -0.159 to 0.879\n",
      "\n",
      "======================================================================\n",
      " ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      " Files created:\n",
      "   - glassdoor_health_care_reviews_with_sentiment.csv (data with sentiment)\n",
      "   - glassdoor_healthcare_sentiment_analysis.png (6 charts)\n",
      "\n",
      " Key findings:\n",
      "   - Total reviews analyzed: 1,500\n",
      "   - Average COMBINED sentiment: 0.320\n",
      "   - Average PROS sentiment: 0.623\n",
      "   - Average CONS sentiment: 0.016\n",
      "   - Most positive company: Boston Scientific (0.353)\n",
      "   - Most negative company: Roche (0.295)\n",
      "   - Positive reviews: 1,268 (84.5%)\n",
      "   - Negative reviews: 122 (8.1%)\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SENTIMENT ANALYSIS FOR GLASSDOOR HEALTHCARE REVIEWS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GLASSDOOR HEALTHCARE SENTIMENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD YOUR DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Loading Glassdoor Healthcare reviews...\")\n",
    "\n",
    "\n",
    "df = pd.read_csv('glassdoor_health_care_reviews.csv')\n",
    "\n",
    "print(f\"âœ“ Loaded {len(df):,} reviews\")\n",
    "print(f\"\\nColumns in your data:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: INITIALIZE SENTIMENT ANALYZER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Initializing sentiment analyzer...\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "print(\" Ready to analyze!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: ANALYZE SENTIMENT FOR PROS AND CONS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n Analyzing {len(df):,} reviews...\")\n",
    "print(\"Analyzing both PROS and CONS sections...\")\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    # Analyze PROS\n",
    "    pros_text = row['pros_text']\n",
    "    if pd.isna(pros_text) or str(pros_text).strip() == \"\" or str(pros_text) == \"N/A\":\n",
    "        pros_score = 0.0\n",
    "        pros_label = 'Neutral'\n",
    "    else:\n",
    "        pros_scores = analyzer.polarity_scores(str(pros_text))\n",
    "        pros_score = pros_scores['compound']\n",
    "        pros_label = 'Positive' if pros_score >= 0.05 else ('Negative' if pros_score <= -0.05 else 'Neutral')\n",
    "    \n",
    "    # Analyze CONS\n",
    "    cons_text = row['cons_text']\n",
    "    if pd.isna(cons_text) or str(cons_text).strip() == \"\" or str(cons_text) == \"N/A\":\n",
    "        cons_score = 0.0\n",
    "        cons_label = 'Neutral'\n",
    "    else:\n",
    "        cons_scores = analyzer.polarity_scores(str(cons_text))\n",
    "        cons_score = cons_scores['compound']\n",
    "        cons_label = 'Positive' if cons_score >= 0.05 else ('Negative' if cons_score <= -0.05 else 'Neutral')\n",
    "    \n",
    "    # Calculate COMBINED sentiment (average of pros and cons)\n",
    "    combined_score = (pros_score + cons_score) / 2\n",
    "    combined_label = 'Positive' if combined_score >= 0.05 else ('Negative' if combined_score <= -0.05 else 'Neutral')\n",
    "    \n",
    "    results.append({\n",
    "        'pros_sentiment_score': pros_score,\n",
    "        'pros_sentiment_label': pros_label,\n",
    "        'cons_sentiment_score': cons_score,\n",
    "        'cons_sentiment_label': cons_label,\n",
    "        'combined_sentiment_score': combined_score,\n",
    "        'combined_sentiment_label': combined_label\n",
    "    })\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"  Processed {idx + 1:,}/{len(df):,} reviews...\")\n",
    "\n",
    "print(f\" Completed analyzing {len(df):,} reviews!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: ADD RESULTS TO DATAFRAME\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Adding sentiment results to dataframe...\")\n",
    "\n",
    "# Convert results to dataframe\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "\n",
    "# Add to original dataframe\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "print(\" Sentiment scores added!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: SHOW RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n COMBINED Sentiment Distribution:\")\n",
    "print(df['combined_sentiment_label'].value_counts())\n",
    "\n",
    "print(\"\\n COMBINED Sentiment Percentages:\")\n",
    "sentiment_pct = df['combined_sentiment_label'].value_counts(normalize=True) * 100\n",
    "for label, pct in sentiment_pct.items():\n",
    "    print(f\"  {label}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\n Average Sentiment Scores:\")\n",
    "print(f\"   PROS:     {df['pros_sentiment_score'].mean():.3f}\")\n",
    "print(f\"   CONS:     {df['cons_sentiment_score'].mean():.3f}\")\n",
    "print(f\"   COMBINED: {df['combined_sentiment_score'].mean():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: SENTIMENT BY COMPANY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SENTIMENT BY COMPANY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "company_stats = df.groupby('company_name').agg({\n",
    "    'combined_sentiment_score': 'mean',\n",
    "    'review_id': 'count',\n",
    "    'overall_rating': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "company_stats.columns = ['Avg Sentiment', 'Review Count', 'Avg Rating']\n",
    "company_stats = company_stats.sort_values('Avg Sentiment', ascending=False)\n",
    "\n",
    "print(\"\\n\", company_stats)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: SHOW EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"examples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Most Positive Reviews:\")\n",
    "top_positive = df.nlargest(3, 'combined_sentiment_score')\n",
    "for idx, row in top_positive.iterrows():\n",
    "    print(f\"\\n  Company: {row['company_name']}\")\n",
    "    print(f\"  Job Title: {row['job_title']}\")\n",
    "    print(f\"  Score: {row['combined_sentiment_score']:.3f}\")\n",
    "    print(f\"  Pros: {str(row['pros_text'])[:100]}...\")\n",
    "    print(f\"  Cons: {str(row['cons_text'])[:100]}...\")\n",
    "\n",
    "print(\"\\n\\n Most Negative Reviews:\")\n",
    "top_negative = df.nsmallest(3, 'combined_sentiment_score')\n",
    "for idx, row in top_negative.iterrows():\n",
    "    print(f\"\\n  Company: {row['company_name']}\")\n",
    "    print(f\"  Job Title: {row['job_title']}\")\n",
    "    print(f\"  Score: {row['combined_sentiment_score']:.3f}\")\n",
    "    print(f\"  Pros: {str(row['pros_text'])[:100]}...\")\n",
    "    print(f\"  Cons: {str(row['cons_text'])[:100]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create figure with multiple subplots\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.suptitle('Glassdoor Healthcare Sentiment Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Chart 1: Combined Sentiment Distribution\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "sentiment_counts = df['combined_sentiment_label'].value_counts()\n",
    "colors = {'Positive': '#2ecc71', 'Neutral': '#95a5a6', 'Negative': '#e74c3c'}\n",
    "bar_colors = [colors.get(label, '#3498db') for label in sentiment_counts.index]\n",
    "\n",
    "ax1.bar(sentiment_counts.index, sentiment_counts.values, color=bar_colors)\n",
    "ax1.set_title('Combined Sentiment Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Reviews')\n",
    "ax1.set_xlabel('Sentiment')\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(sentiment_counts.values):\n",
    "    ax1.text(i, v, f'{v:,}\\n({v/len(df)*100:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Chart 2: Pros vs Cons Sentiment\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "comparison_data = pd.DataFrame({\n",
    "    'Pros': [df['pros_sentiment_score'].mean()],\n",
    "    'Cons': [df['cons_sentiment_score'].mean()],\n",
    "    'Combined': [df['combined_sentiment_score'].mean()]\n",
    "})\n",
    "comparison_data.T.plot(kind='bar', ax=ax2, legend=False, color=['#2ecc71', '#e74c3c', '#3498db'])\n",
    "ax2.set_title('Average Sentiment: Pros vs Cons', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average Sentiment Score')\n",
    "ax2.set_xticklabels(['Pros', 'Cons', 'Combined'], rotation=0)\n",
    "ax2.axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Chart 3: Sentiment Score Distribution\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "ax3.hist(df['combined_sentiment_score'], bins=40, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(df['combined_sentiment_score'].mean(), color='red', linestyle='--', \n",
    "           linewidth=2, label=f'Mean: {df[\"combined_sentiment_score\"].mean():.3f}')\n",
    "ax3.set_title('Combined Sentiment Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Sentiment Score')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# Chart 4: Sentiment by Company\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "company_sentiment = df.groupby('company_name')['combined_sentiment_score'].mean().sort_values()\n",
    "colors_comp = ['#e74c3c' if x < -0.05 else '#2ecc71' if x > 0.05 else '#95a5a6' \n",
    "               for x in company_sentiment.values]\n",
    "\n",
    "ax4.barh(company_sentiment.index, company_sentiment.values, color=colors_comp)\n",
    "ax4.set_title('Average Sentiment by Company', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Average Sentiment Score')\n",
    "ax4.axvline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax4.grid(alpha=0.3, axis='x')\n",
    "\n",
    "# Add review counts\n",
    "for i, (idx, value) in enumerate(company_sentiment.items()):\n",
    "    count = len(df[df['company_name'] == idx])\n",
    "    ax4.text(value, i, f' n={count}', va='center', fontsize=8)\n",
    "\n",
    "# Chart 5: Rating vs Sentiment Correlation\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.scatter(df['overall_rating'], df['combined_sentiment_score'], alpha=0.3, s=20)\n",
    "ax5.set_title('Overall Rating vs Sentiment Score', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Overall Rating (Stars)')\n",
    "ax5.set_ylabel('Sentiment Score')\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# Add correlation\n",
    "correlation = df['overall_rating'].corr(df['combined_sentiment_score'])\n",
    "ax5.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "        transform=ax5.transAxes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Chart 6: Top/Bottom Companies\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "top_3 = company_sentiment.tail(3)\n",
    "bottom_3 = company_sentiment.head(3)\n",
    "combined_top_bottom = pd.concat([bottom_3, top_3])\n",
    "\n",
    "colors_tb = ['#e74c3c']*len(bottom_3) + ['#2ecc71']*len(top_3)\n",
    "ax6.barh(range(len(combined_top_bottom)), combined_top_bottom.values, color=colors_tb)\n",
    "ax6.set_yticks(range(len(combined_top_bottom)))\n",
    "ax6.set_yticklabels(combined_top_bottom.index, fontsize=9)\n",
    "ax6.set_title('Top 3 & Bottom 3 Companies', fontsize=12, fontweight='bold')\n",
    "ax6.set_xlabel('Average Sentiment Score')\n",
    "ax6.axvline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax6.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('glassdoor_healthcare_sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\" Saved visualization: glassdoor_healthcare_sentiment_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: SAVE RESULTS TO CSV\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_file = 'glassdoor_health_care_reviews_with_sentiment.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved results to: {output_file}\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(f\"  - pros_sentiment_score\")\n",
    "print(f\"  - pros_sentiment_label\")\n",
    "print(f\"  - cons_sentiment_score\")\n",
    "print(f\"  - cons_sentiment_label\")\n",
    "print(f\"  - combined_sentiment_score (MAIN METRIC)\")\n",
    "print(f\"  - combined_sentiment_label\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: ADDITIONAL INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADDITIONAL INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Correlation between rating and sentiment\n",
    "correlation = df['overall_rating'].corr(df['combined_sentiment_score'])\n",
    "print(f\"\\n Correlation between star rating and sentiment: {correlation:.3f}\")\n",
    "\n",
    "# Sentiment by job title (top 10)\n",
    "print(\"\\n Sentiment by Job Title (Top 10 most common):\")\n",
    "job_sentiment = df.groupby('job_title').agg({\n",
    "    'combined_sentiment_score': 'mean',\n",
    "    'review_id': 'count'\n",
    "})\n",
    "job_sentiment.columns = ['Avg Sentiment', 'Count']\n",
    "job_sentiment = job_sentiment[job_sentiment['Count'] >= 3]  # At least 3 reviews\n",
    "job_sentiment = job_sentiment.sort_values('Avg Sentiment', ascending=False).head(10)\n",
    "print(job_sentiment.round(3))\n",
    "\n",
    "# Time analysis (if date is available)\n",
    "if 'review_date' in df.columns:\n",
    "    try:\n",
    "        df['review_date'] = pd.to_datetime(df['review_date'])\n",
    "        df['year_month'] = df['review_date'].dt.to_period('M')\n",
    "        \n",
    "        temporal = df.groupby('year_month')['combined_sentiment_score'].mean()\n",
    "        print(f\"\\n Temporal Analysis:\")\n",
    "        print(f\"  Data spans from {temporal.index.min()} to {temporal.index.max()}\")\n",
    "        print(f\"  Sentiment ranges from {temporal.min():.3f} to {temporal.max():.3f}\")\n",
    "    except:\n",
    "        print(\"\\n Could not parse review dates for temporal analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    " Files created:\n",
    "   - glassdoor_health_care_reviews_with_sentiment.csv (data with sentiment)\n",
    "   - glassdoor_healthcare_sentiment_analysis.png (6 charts)\n",
    "\n",
    " Key findings:\n",
    "   - Total reviews analyzed: {len(df):,}\n",
    "   - Average COMBINED sentiment: {df['combined_sentiment_score'].mean():.3f}\n",
    "   - Average PROS sentiment: {df['pros_sentiment_score'].mean():.3f}\n",
    "   - Average CONS sentiment: {df['cons_sentiment_score'].mean():.3f}\n",
    "   - Most positive company: {company_sentiment.idxmax()} ({company_sentiment.max():.3f})\n",
    "   - Most negative company: {company_sentiment.idxmin()} ({company_sentiment.min():.3f})\n",
    "   - Positive reviews: {(df['combined_sentiment_label']=='Positive').sum():,} ({(df['combined_sentiment_label']=='Positive').sum()/len(df)*100:.1f}%)\n",
    "   - Negative reviews: {(df['combined_sentiment_label']=='Negative').sum():,} ({(df['combined_sentiment_label']=='Negative').sum()/len(df)*100:.1f}%)\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
